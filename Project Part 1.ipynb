{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1b1301",
   "metadata": {},
   "source": [
    "# Team members\n",
    "\n",
    "Berkin Öztürk & Berker Uğraş"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c40a18a",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "\n",
    "At first, we imported torch, pandas and matplotlib libraries to load the csv files and align the input & output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922fe47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch;\n",
    "import pandas as pd;\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c10bf16",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "\n",
    "Since we have to align them according to dates in the data_y file, we defined a while loop to match the corresponding dates and drop the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1d3c27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([392, 393, 400,  ..., 461, 450, 431])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indic = pd.read_csv('data_X.csv')\n",
    "results=pd.read_csv('data_Y.csv')\n",
    "\n",
    "measurements=indic.iloc[0:,1:].values\n",
    "results=results.iloc[0:,1:].values\n",
    "\n",
    "measurements=torch.from_numpy(measurements)\n",
    "results=torch.from_numpy(results)\n",
    "\n",
    "measurements=measurements[4325:len(measurements):120]\n",
    "newMeasurements=torch.zeros(len(results),len(measurements[0]))\n",
    "\n",
    "\n",
    "a=0\n",
    "i=0\n",
    "while i<len(newMeasurements):#4325,len(measurements),120\n",
    "    if(a>=len(measurements)):\n",
    "        break\n",
    "    newMeasurements[i]=measurements[a]\n",
    "    a=a+1\n",
    "    if(a!=0 and a%6==0):\n",
    "        newMeasurements[i+1]=measurements[a]\n",
    "        i=i+1\n",
    "        a=a+6   \n",
    "       \n",
    "    i=i+1\n",
    "newMeasurements.shape\n",
    "results=torch.reshape(results,(-1,))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7dd1a0",
   "metadata": {},
   "source": [
    "# Step 3 \n",
    "\n",
    "We wrote a generator function to load batches of data. It receives the data inputs as arguments, outputs, and the batch size and yields a batch of examples at every call, where the batch is a tuple of inputs and outputs in the batch. Since batches shall not always be the same across the epochs, we shuffled the data by using the .randperm function to have random indexes and stored them in the batch_idx list. And by using these indexes, which are in the batch_idx, we provided the randomness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5662081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator Function\n",
    "def iter_data(inputs,outputs,batch_size):\n",
    "    n=inputs.shape[0]\n",
    "    idx=torch.randperm(n)\n",
    "    for i in range(0,n,batch_size):\n",
    "        batch_end=min(i+batch_size,n)\n",
    "        batch_idx=idx[i:batch_end]\n",
    "        batch=inputs[batch_idx[0:]],outputs[batch_idx[0:]]\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a87b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches=iter_data(newMeasurements[:30],results[:30],7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85301d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[236.0000, 238.0000, 245.0000, 323.0000, 320.0000, 318.0000, 522.0000,\n",
       "          501.0000, 524.0000, 343.0000, 371.0000, 344.0000, 264.0000, 263.0000,\n",
       "          265.0000, 195.7100,   7.9700],\n",
       "         [229.0000, 234.0000, 230.0000, 315.0000, 344.0000, 323.0000, 515.0000,\n",
       "          573.0000, 509.0000, 364.0000, 349.0000, 361.0000, 248.0000, 240.0000,\n",
       "          246.0000, 162.5800,   6.3600],\n",
       "         [298.0000, 298.0000, 297.0000, 369.0000, 338.0000, 337.0000, 530.0000,\n",
       "          586.0000, 884.0000, 339.0000, 332.0000, 333.0000, 213.0000, 230.0000,\n",
       "          214.0000, 165.5800,   7.7100],\n",
       "         [211.0000, 206.0000, 207.0000, 309.0000, 302.0000, 308.0000, 524.0000,\n",
       "          497.0000, 498.0000, 395.0000, 376.0000, 365.0000, 251.0000, 237.0000,\n",
       "          264.0000, 193.8800,   9.1900],\n",
       "         [183.0000, 211.0000, 210.0000, 311.0000, 309.0000, 305.0000, 502.0000,\n",
       "          503.0000, 541.0000, 361.0000, 342.0000, 347.0000, 260.0000, 260.0000,\n",
       "          268.0000, 196.0600,   7.1700],\n",
       "         [230.0000, 230.0000, 229.0000, 299.0000, 368.0000, 311.0000, 544.0000,\n",
       "          528.0000, 550.0000, 338.0000, 336.0000, 330.0000, 216.0000, 217.0000,\n",
       "          199.0000, 164.6700,   7.7800],\n",
       "         [228.0000, 229.0000, 225.0000, 304.0000, 309.0000, 311.0000, 531.0000,\n",
       "          533.0000, 525.0000, 340.0000, 379.0000, 358.0000, 270.0000, 270.0000,\n",
       "          273.0000, 150.5500,   8.4600]]),\n",
       " tensor([400, 350, 379, 405, 405, 319, 350]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca58db1",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "\n",
    "We defined the linear model. It takes as arguments the input data and the model parameters (weights and bias) and returns the output predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fd6b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear_Reg(inputs,weights,bias):\n",
    "        return inputs.matmul(weights)+bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61899394",
   "metadata": {},
   "source": [
    "# Step 5\n",
    "\n",
    "In step 5, to test our linear model, we used random weight & bias parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84c2aaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2554.0737, 2461.5054, 2473.9521,  ..., 2403.5745, 2486.7502,\n",
      "        2476.7771], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#random w and b parameeter\n",
    "values=torch.rand(17)\n",
    "w=values.clone().detach().requires_grad_(True)\n",
    "b=torch.tensor([0.],requires_grad=True)\n",
    "\n",
    "y_hat=Linear_Reg(newMeasurements,w,b)\n",
    "print(y_hat-results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fff587d",
   "metadata": {},
   "source": [
    "# Step 6\n",
    "\n",
    "In this step, we calculated the square error and did back propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "586b9955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradients\n",
    "err=torch.mean((y_hat-results)**2)\n",
    "err\n",
    "err.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a11400",
   "metadata": {},
   "source": [
    "# Step 7\n",
    "\n",
    "We defined the our loss function as the average squared error of the predictions – the function taking in the\n",
    "predictions and true labels and returning the value of the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cf8232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function loss_func(labels, preds) -> error\n",
    "# --- YOUR CODE HERE --\n",
    "\n",
    "def Loss_Function(labels,preds):\n",
    "    return torch.mean(0.5*(preds-labels)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68bdda3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3090058., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loss_Function(y_hat,results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02293c59",
   "metadata": {},
   "source": [
    "# Step 8 \n",
    "\n",
    "We created our SGD function -minibatch stochastic gradient descent. Since SGD is an operation in the optimization procedure and as such shall not be part of the computational graph - we do not need to update parameter gradients, for this reason we used torch.no_grad function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01162198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimization Algorithm Minibatch Stochastic\n",
    "def sgd_step(params, learn_rate, batch_size):\n",
    "    for param in params:\n",
    "        with torch.no_grad():\n",
    "            param-=learn_rate/batch_size * param.grad\n",
    "            param.grad.zero_()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e68478dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:tensor([0.6339, 0.6012, 0.9160, 0.5382, 0.2155, 0.8245, 0.6229, 0.8499, 0.0625,\n",
      "        0.0993, 0.7659, 0.8522, 0.0017, 0.9627, 0.2477, 0.6764, 0.6484],\n",
      "       requires_grad=True),tensor([0.], requires_grad=True)\n",
      "after:tensor([-40.7684, -40.7413, -40.5195, -57.4819, -57.6550, -57.2005, -82.6713,\n",
      "        -82.4041, -83.3058, -57.6694, -57.0169, -57.1244, -41.3627, -40.3885,\n",
      "        -41.1595, -28.2462,  -0.5923], requires_grad=True),tensor([-0.1654], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(f'before:{w},{b}')\n",
    "sgd_step([w,b],0.001,30)\n",
    "print(f'after:{w},{b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647c67fb",
   "metadata": {},
   "source": [
    "# Step 9\n",
    "\n",
    "At this step, we defined our training procedure. We also defined number of epochs, batch size and learning rate values as it should be at every training process. We set our hyper parameters (learning rate, batch size , number of epochs) manually according to result of loss values. In the training process, we updated the model parameters by using our optimizer (minibatch stochastic gradient descent). To monitor the training loss evaluation we benefit from matplotlib and printed the loss value after every epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "923b5169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.4457, -1.1251,  0.8185,  0.3452,  1.3005, -1.7227,  0.6513,  1.1744,\n",
      "        -0.0298,  0.4271, -0.8395,  0.1696, -1.1807,  1.1566, -0.2728, -0.3074,\n",
      "         0.0478], requires_grad=True)\n",
      "loss 7578.75537109375\n",
      "loss 7280.001953125\n",
      "loss 5647.16845703125\n",
      "loss 6154.19287109375\n",
      "loss 4534.765625\n",
      "loss 4082.85009765625\n",
      "loss 7085.353515625\n",
      "loss 5151.24462890625\n",
      "loss 4653.08935546875\n",
      "loss 4367.94775390625\n",
      "loss 4921.05322265625\n",
      "loss 3719.779541015625\n",
      "loss 8200.4716796875\n",
      "loss 4082.18310546875\n",
      "loss 2481.304443359375\n",
      "loss 4312.50634765625\n",
      "loss 2846.50341796875\n",
      "loss 3919.49169921875\n",
      "loss 2282.142333984375\n",
      "loss 1982.7052001953125\n",
      "loss 1930.4478759765625\n",
      "loss 3125.35546875\n",
      "loss 1925.7115478515625\n",
      "loss 2671.35009765625\n",
      "loss 2053.06884765625\n",
      "loss 5848.57666015625\n",
      "loss 3081.61083984375\n",
      "loss 2719.98291015625\n",
      "loss 5394.25\n",
      "loss 2995.067626953125\n",
      "loss 1591.318359375\n",
      "loss 1407.288330078125\n",
      "loss 4690.01171875\n",
      "loss 3246.86474609375\n",
      "loss 2206.63427734375\n",
      "loss 1919.402587890625\n",
      "loss 775.8829956054688\n",
      "loss 12733.5107421875\n",
      "loss 4528.94921875\n",
      "loss 2245.0791015625\n",
      "loss 1759.3939208984375\n",
      "loss 2607.14990234375\n",
      "loss 3154.307861328125\n",
      "loss 2364.328857421875\n",
      "loss 1355.341796875\n",
      "loss 3619.0048828125\n",
      "loss 1864.1396484375\n",
      "loss 1877.385986328125\n",
      "loss 2449.422119140625\n",
      "loss 2335.1826171875\n",
      "loss 1352.3309326171875\n",
      "loss 2347.447021484375\n",
      "loss 997.2665405273438\n",
      "loss 1212.829833984375\n",
      "loss 1597.675537109375\n",
      "loss 1537.798583984375\n",
      "loss 1395.401611328125\n",
      "loss 1191.6636962890625\n",
      "loss 2504.1845703125\n",
      "loss 2224.690185546875\n",
      "loss 1187.645263671875\n",
      "loss 1365.9512939453125\n",
      "loss 1214.15087890625\n",
      "loss 1949.87353515625\n",
      "loss 1634.3115234375\n",
      "loss 2507.877685546875\n",
      "loss 1337.2099609375\n",
      "loss 1116.976318359375\n",
      "loss 758.3017578125\n",
      "loss 1161.976806640625\n",
      "loss 792.4451904296875\n",
      "loss 1449.1898193359375\n",
      "loss 1537.3905029296875\n",
      "loss 1218.888427734375\n",
      "loss 953.319580078125\n",
      "loss 2410.59765625\n",
      "loss 1181.290771484375\n",
      "loss 1132.2655029296875\n",
      "loss 669.5540161132812\n",
      "loss 1925.4510498046875\n",
      "loss 2120.940185546875\n",
      "loss 1120.34326171875\n",
      "loss 1536.0843505859375\n",
      "loss 886.653076171875\n",
      "loss 1426.816162109375\n",
      "loss 1442.753662109375\n",
      "loss 1872.7894287109375\n",
      "loss 2399.96826171875\n",
      "loss 1192.4166259765625\n",
      "loss 1501.340087890625\n",
      "loss 1469.8502197265625\n",
      "loss 636.21435546875\n",
      "loss 830.67236328125\n",
      "loss 629.5029907226562\n",
      "loss 958.3775634765625\n",
      "loss 1659.1102294921875\n",
      "loss 1272.655029296875\n",
      "loss 863.134521484375\n",
      "loss 923.0311279296875\n",
      "loss 986.8276977539062\n",
      "loss 1215.03271484375\n",
      "loss 1496.860107421875\n",
      "loss 964.8823852539062\n",
      "loss 789.243408203125\n",
      "loss 1606.4346923828125\n",
      "loss 993.3984375\n",
      "loss 1158.56982421875\n",
      "loss 816.8643798828125\n",
      "loss 1120.230712890625\n",
      "loss 883.3613891601562\n",
      "loss 521.765625\n",
      "loss 1303.2427978515625\n",
      "loss 846.8248291015625\n",
      "loss 891.1861572265625\n",
      "loss 1015.8665771484375\n",
      "loss 775.0467529296875\n",
      "loss 488.6650695800781\n",
      "loss 357.6306457519531\n",
      "loss 2979.18212890625\n",
      "loss 673.008544921875\n",
      "loss 1041.045166015625\n",
      "loss 1277.0657958984375\n",
      "loss 580.5352172851562\n",
      "loss 671.3992309570312\n",
      "loss 882.75146484375\n",
      "loss 1124.07763671875\n",
      "loss 971.1817016601562\n",
      "loss 728.8589477539062\n",
      "loss 1249.6136474609375\n",
      "loss 1037.8701171875\n",
      "loss 585.819580078125\n",
      "loss 564.7940673828125\n",
      "loss 911.0924072265625\n",
      "loss 873.0165405273438\n",
      "loss 1077.9384765625\n",
      "loss 791.6188354492188\n",
      "loss 599.657958984375\n",
      "loss 856.3615112304688\n",
      "loss 701.7750244140625\n",
      "loss 611.8463134765625\n",
      "loss 1093.059326171875\n",
      "loss 683.7987060546875\n",
      "loss 1112.2481689453125\n",
      "loss 829.0018920898438\n",
      "loss 433.07843017578125\n",
      "loss 706.4606323242188\n",
      "loss 1466.8955078125\n",
      "loss 999.6841430664062\n",
      "loss 1272.8924560546875\n",
      "loss 694.1887817382812\n",
      "loss 827.6403198242188\n",
      "loss 935.0189208984375\n",
      "loss 627.4254760742188\n",
      "loss 583.1854248046875\n",
      "loss 642.40966796875\n",
      "loss 571.2573852539062\n",
      "loss 745.545166015625\n",
      "loss 857.9511108398438\n",
      "loss 779.9466552734375\n",
      "loss 1111.52294921875\n",
      "loss 672.4708251953125\n",
      "loss 618.7189331054688\n",
      "loss 534.473388671875\n",
      "loss 436.8184509277344\n",
      "loss 1140.038330078125\n",
      "loss 711.1607055664062\n",
      "loss 947.0266723632812\n",
      "loss 657.3348388671875\n",
      "loss 697.5517578125\n",
      "loss 414.9626770019531\n",
      "loss 614.6171875\n",
      "loss 568.644775390625\n",
      "loss 642.9135131835938\n",
      "loss 632.8925170898438\n",
      "loss 590.9932861328125\n",
      "loss 631.9482421875\n",
      "loss 700.4852905273438\n",
      "loss 557.3515014648438\n",
      "loss 661.65087890625\n",
      "loss 723.451171875\n",
      "loss 749.8161010742188\n",
      "loss 479.6546936035156\n",
      "loss 671.81201171875\n",
      "loss 670.778076171875\n",
      "loss 518.072998046875\n",
      "loss 584.156005859375\n",
      "loss 723.530517578125\n",
      "loss 674.843017578125\n",
      "loss 630.4197387695312\n",
      "loss 748.921142578125\n",
      "loss 770.1461791992188\n",
      "loss 755.8438720703125\n",
      "loss 556.6622314453125\n",
      "loss 530.9081420898438\n",
      "loss 470.5799560546875\n",
      "loss 853.47216796875\n",
      "loss 436.28863525390625\n",
      "loss 450.25970458984375\n",
      "loss 498.95123291015625\n",
      "loss 953.742919921875\n",
      "loss 454.27294921875\n",
      "loss 621.0369873046875\n",
      "loss 559.9619750976562\n",
      "loss 625.6962280273438\n",
      "loss 774.6424560546875\n",
      "loss 631.3432006835938\n",
      "loss 827.9055786132812\n",
      "loss 531.9547729492188\n",
      "loss 504.82196044921875\n",
      "loss 423.2825927734375\n",
      "loss 1206.7025146484375\n",
      "loss 789.47412109375\n",
      "loss 488.72821044921875\n",
      "loss 807.928955078125\n",
      "loss 456.5302734375\n",
      "loss 645.7332763671875\n",
      "loss 267.52325439453125\n",
      "loss 639.7173461914062\n",
      "loss 434.5686950683594\n",
      "loss 591.52587890625\n",
      "loss 651.2486572265625\n",
      "loss 642.6483154296875\n",
      "loss 318.1639404296875\n",
      "loss 832.8990478515625\n",
      "loss 484.4427795410156\n",
      "loss 637.137939453125\n",
      "loss 674.1139526367188\n",
      "loss 699.1865234375\n",
      "loss 798.3502807617188\n",
      "loss 651.532470703125\n",
      "loss 405.9271545410156\n",
      "loss 970.9083251953125\n",
      "loss 549.32470703125\n",
      "loss 673.8160400390625\n",
      "loss 562.9437255859375\n",
      "loss 795.920654296875\n",
      "loss 553.4051513671875\n",
      "loss 498.9706115722656\n",
      "loss 500.78228759765625\n",
      "loss 611.7596435546875\n",
      "loss 288.51226806640625\n",
      "loss 336.77001953125\n",
      "loss 612.19189453125\n",
      "loss 571.8634033203125\n",
      "loss 573.7384033203125\n",
      "loss 628.9107055664062\n",
      "loss 491.069091796875\n",
      "loss 568.672119140625\n",
      "loss 526.6136474609375\n",
      "loss 496.05389404296875\n",
      "loss 1027.2344970703125\n",
      "loss 740.2350463867188\n",
      "loss 517.9444580078125\n",
      "loss 622.4493408203125\n",
      "loss 532.523193359375\n",
      "loss 506.1440734863281\n",
      "loss 761.5390014648438\n",
      "loss 587.79638671875\n",
      "loss 506.6270751953125\n",
      "loss 491.2770080566406\n",
      "loss 439.83428955078125\n",
      "loss 570.595947265625\n",
      "loss 599.782470703125\n",
      "loss 674.1204223632812\n",
      "loss 671.8214111328125\n",
      "loss 408.30133056640625\n",
      "loss 691.7996826171875\n",
      "loss 733.1337890625\n",
      "loss 448.68096923828125\n",
      "loss 386.78240966796875\n",
      "loss 637.4488525390625\n",
      "loss 400.0603332519531\n",
      "loss 494.7890930175781\n",
      "loss 688.7828369140625\n",
      "loss 458.54339599609375\n",
      "loss 493.26666259765625\n",
      "loss 193.71719360351562\n",
      "loss 527.93359375\n",
      "loss 402.50982666015625\n",
      "loss 466.6632385253906\n",
      "loss 416.7674865722656\n",
      "loss 490.29901123046875\n",
      "loss 600.9713134765625\n",
      "loss 330.11761474609375\n",
      "loss 680.4910278320312\n",
      "loss 326.18597412109375\n",
      "loss 471.58642578125\n",
      "loss 423.29388427734375\n",
      "loss 473.48248291015625\n",
      "loss 365.5987854003906\n",
      "loss 509.4580383300781\n",
      "loss 330.53118896484375\n",
      "loss 577.5276489257812\n",
      "loss 510.13275146484375\n",
      "loss 503.8135986328125\n",
      "loss 1016.75927734375\n",
      "loss 601.48779296875\n",
      "loss 602.5723266601562\n",
      "loss 523.818359375\n",
      "loss 443.6919860839844\n",
      "loss 362.1024169921875\n",
      "loss 485.9410705566406\n",
      "loss 510.0736083984375\n",
      "loss 287.66766357421875\n",
      "loss 560.2119750976562\n",
      "loss 382.9508056640625\n",
      "loss 728.821533203125\n",
      "loss 386.516845703125\n",
      "loss 884.3547973632812\n",
      "loss 440.58038330078125\n",
      "loss 557.2281494140625\n",
      "loss 452.030517578125\n",
      "loss 449.0452575683594\n",
      "loss 836.6083984375\n",
      "loss 474.2138366699219\n",
      "loss 311.799560546875\n",
      "loss 822.658935546875\n",
      "loss 508.39178466796875\n",
      "loss 337.76873779296875\n",
      "loss 356.7409973144531\n",
      "loss 564.8561401367188\n",
      "loss 327.75408935546875\n",
      "loss 356.98211669921875\n",
      "loss 395.87286376953125\n",
      "loss 895.12060546875\n",
      "loss 565.763916015625\n",
      "loss 361.4700012207031\n",
      "loss 318.56689453125\n",
      "loss 417.7058410644531\n",
      "loss 439.8578796386719\n",
      "loss 523.71484375\n",
      "loss 433.85009765625\n",
      "loss 547.5484008789062\n",
      "loss 561.9784545898438\n",
      "loss 518.8441162109375\n",
      "loss 522.4366455078125\n",
      "loss 469.8146667480469\n",
      "loss 239.61898803710938\n",
      "loss 428.06182861328125\n",
      "loss 652.47119140625\n",
      "loss 656.3073120117188\n",
      "loss 294.89404296875\n",
      "loss 499.8526306152344\n",
      "loss 371.7877197265625\n",
      "loss 765.2356567382812\n",
      "loss 354.5225524902344\n",
      "loss 580.924072265625\n",
      "loss 439.03118896484375\n",
      "loss 340.1300048828125\n",
      "loss 299.5853271484375\n",
      "loss 906.2359008789062\n",
      "loss 498.4021301269531\n",
      "loss 362.2047119140625\n",
      "loss 499.1597595214844\n",
      "loss 395.1141052246094\n",
      "loss 358.10888671875\n",
      "loss 512.735107421875\n",
      "loss 504.2313232421875\n",
      "loss 418.70733642578125\n",
      "loss 406.96319580078125\n",
      "loss 539.0792236328125\n",
      "loss 490.441650390625\n",
      "loss 359.6741943359375\n",
      "loss 645.13916015625\n",
      "loss 561.0980224609375\n",
      "loss 319.03521728515625\n",
      "loss 467.7740478515625\n",
      "loss 488.46661376953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 397.47503662109375\n",
      "loss 631.4730224609375\n",
      "loss 397.8879699707031\n",
      "loss 305.6984558105469\n",
      "loss 259.0244140625\n",
      "loss 345.6018371582031\n",
      "loss 428.478759765625\n",
      "loss 451.8051452636719\n",
      "loss 497.575439453125\n",
      "loss 501.2178039550781\n",
      "loss 392.7601623535156\n",
      "loss 483.99456787109375\n",
      "loss 598.4249877929688\n",
      "loss 330.0410461425781\n",
      "loss 387.8362121582031\n",
      "loss 548.9459228515625\n",
      "loss 420.23858642578125\n",
      "loss 606.2246704101562\n",
      "loss 536.9953002929688\n",
      "loss 429.40716552734375\n",
      "loss 308.9372863769531\n",
      "loss 489.7255859375\n",
      "loss 352.02532958984375\n",
      "loss 479.14501953125\n",
      "loss 295.0059814453125\n",
      "loss 484.5189514160156\n",
      "loss 428.7471618652344\n",
      "loss 363.4444274902344\n",
      "loss 366.30816650390625\n",
      "loss 680.0874633789062\n",
      "loss 474.7491149902344\n",
      "loss 273.18975830078125\n",
      "loss 316.2249755859375\n",
      "loss 234.78182983398438\n",
      "loss 647.1820678710938\n",
      "loss 380.2120361328125\n",
      "loss 579.5480346679688\n",
      "loss 478.7327880859375\n",
      "loss 682.2523193359375\n",
      "loss 407.84698486328125\n",
      "loss 290.7513732910156\n",
      "loss 441.5628967285156\n",
      "loss 802.8681030273438\n",
      "loss 485.734375\n",
      "loss 309.33331298828125\n",
      "loss 383.5966491699219\n",
      "loss 493.3411560058594\n",
      "loss 474.0533142089844\n",
      "loss 253.86358642578125\n",
      "loss 316.1549987792969\n",
      "loss 326.565673828125\n",
      "loss 407.0282897949219\n",
      "loss 786.6524658203125\n",
      "loss 313.220947265625\n",
      "loss 624.9166259765625\n",
      "loss 905.1575317382812\n",
      "loss 375.6980895996094\n",
      "loss 445.61773681640625\n",
      "loss 347.6485290527344\n",
      "loss 520.1290893554688\n",
      "loss 423.1317443847656\n",
      "loss 583.8214111328125\n",
      "loss 349.44586181640625\n",
      "loss 415.3872375488281\n",
      "loss 321.961181640625\n",
      "loss 580.6261596679688\n",
      "loss 378.6415100097656\n",
      "loss 372.1264953613281\n",
      "loss 276.754150390625\n",
      "loss 274.927978515625\n",
      "loss 379.0745544433594\n",
      "loss 465.6531677246094\n",
      "loss 455.3327331542969\n",
      "loss 271.62091064453125\n",
      "loss 431.63519287109375\n",
      "loss 346.5643310546875\n",
      "loss 432.3824157714844\n",
      "loss 474.5628967285156\n",
      "loss 469.4478759765625\n",
      "loss 484.4498596191406\n",
      "loss 470.4132385253906\n",
      "loss 437.2985534667969\n",
      "loss 324.75335693359375\n",
      "loss 374.7462463378906\n",
      "loss 391.57647705078125\n",
      "loss 404.36761474609375\n",
      "loss 478.5691833496094\n",
      "loss 287.584228515625\n",
      "loss 386.9403991699219\n",
      "loss 972.790283203125\n",
      "loss 389.317626953125\n",
      "loss 409.8831787109375\n",
      "loss 487.8229064941406\n",
      "loss 423.1897277832031\n",
      "loss 570.9166870117188\n",
      "loss 391.52374267578125\n",
      "loss 252.63043212890625\n",
      "loss 427.9333801269531\n",
      "loss 475.76324462890625\n",
      "loss 531.593017578125\n",
      "loss 504.275634765625\n",
      "loss 403.2521667480469\n",
      "loss 391.58148193359375\n",
      "loss 288.1923522949219\n",
      "loss 394.9988098144531\n",
      "loss 531.666748046875\n",
      "loss 348.42779541015625\n",
      "loss 367.4217834472656\n",
      "loss 544.7271728515625\n",
      "loss 446.8062438964844\n",
      "loss 428.0515441894531\n",
      "loss 285.1489562988281\n",
      "loss 571.4253540039062\n",
      "loss 498.3646545410156\n",
      "loss 469.7679748535156\n",
      "loss 332.77978515625\n",
      "loss 524.234130859375\n",
      "loss 373.9258728027344\n",
      "loss 413.739501953125\n",
      "loss 499.160400390625\n",
      "loss 535.2291259765625\n",
      "loss 290.2507019042969\n",
      "loss 381.12054443359375\n",
      "loss 318.482421875\n",
      "loss 299.3733215332031\n",
      "loss 1231.376220703125\n",
      "loss 365.2851257324219\n",
      "loss 427.9942321777344\n",
      "loss 631.6517333984375\n",
      "loss 455.8717956542969\n",
      "loss 343.96759033203125\n",
      "loss 319.31427001953125\n",
      "loss 1091.41943359375\n",
      "loss 300.8102111816406\n",
      "loss 425.0727844238281\n",
      "loss 310.483154296875\n",
      "loss 484.408203125\n",
      "loss 563.3062133789062\n",
      "loss 293.76922607421875\n",
      "loss 280.2556457519531\n",
      "loss 593.2955322265625\n",
      "loss 359.2258605957031\n",
      "loss 444.5685119628906\n",
      "loss 267.59375\n",
      "loss 357.67181396484375\n",
      "loss 493.8814697265625\n",
      "loss 369.406982421875\n",
      "loss 310.4822998046875\n",
      "loss 273.9602355957031\n",
      "loss 417.5829162597656\n",
      "loss 409.8917541503906\n",
      "loss 304.1660461425781\n",
      "loss 309.91766357421875\n",
      "loss 438.8599548339844\n",
      "loss 479.59674072265625\n",
      "loss 359.8023681640625\n",
      "loss 327.8765869140625\n",
      "loss 348.88177490234375\n",
      "loss 330.039306640625\n",
      "loss 279.9143981933594\n",
      "loss 274.9305725097656\n",
      "loss 643.70654296875\n",
      "loss 351.5924377441406\n",
      "loss 390.73846435546875\n",
      "loss 350.8882141113281\n",
      "loss 403.16876220703125\n",
      "loss 468.9010925292969\n",
      "loss 375.6754150390625\n",
      "loss 282.17889404296875\n",
      "loss 484.70013427734375\n",
      "loss 309.9006042480469\n",
      "loss 363.61834716796875\n",
      "loss 278.3797912597656\n",
      "loss 356.4245910644531\n",
      "loss 461.33013916015625\n",
      "loss 647.3502807617188\n",
      "loss 554.788818359375\n",
      "loss 397.14599609375\n",
      "loss 396.38885498046875\n",
      "loss 440.47320556640625\n",
      "loss 233.23277282714844\n",
      "loss 481.0562744140625\n",
      "loss 495.8013916015625\n",
      "loss 274.86199951171875\n",
      "loss 351.7818603515625\n",
      "loss 916.0482177734375\n",
      "loss 526.6055908203125\n",
      "loss 339.66748046875\n",
      "loss 286.7647399902344\n",
      "loss 492.9802551269531\n",
      "loss 386.3695068359375\n",
      "loss 237.67800903320312\n",
      "loss 415.247314453125\n",
      "loss 337.1147766113281\n",
      "loss 354.4258728027344\n",
      "loss 401.424560546875\n",
      "loss 468.7371826171875\n",
      "loss 445.213623046875\n",
      "loss 426.23602294921875\n",
      "loss 444.5537109375\n",
      "loss 348.5985412597656\n",
      "loss 400.68804931640625\n",
      "loss 318.6712951660156\n",
      "loss 549.4176025390625\n",
      "loss 330.2364501953125\n",
      "loss 369.71630859375\n",
      "loss 478.6291198730469\n",
      "loss 292.30218505859375\n",
      "loss 456.3459167480469\n",
      "loss 446.6188049316406\n",
      "loss 386.5125427246094\n",
      "loss 399.84014892578125\n",
      "loss 293.7700500488281\n",
      "loss 290.54815673828125\n",
      "loss 337.1341857910156\n",
      "loss 409.0534973144531\n",
      "loss 449.3758544921875\n",
      "loss 639.3140258789062\n",
      "loss 383.9265441894531\n",
      "loss 331.8905944824219\n",
      "loss 513.3112182617188\n",
      "loss 324.6481628417969\n",
      "loss 373.29925537109375\n",
      "loss 484.98590087890625\n",
      "loss 371.8038635253906\n",
      "loss 303.695556640625\n",
      "loss 267.9673767089844\n",
      "loss 477.1089172363281\n",
      "loss 557.516845703125\n",
      "loss 631.758056640625\n",
      "loss 281.7588806152344\n",
      "loss 305.1641540527344\n",
      "loss 362.8574523925781\n",
      "loss 307.16485595703125\n",
      "loss 331.1278991699219\n",
      "loss 319.0343322753906\n",
      "loss 509.20654296875\n",
      "loss 339.5059509277344\n",
      "loss 390.29949951171875\n",
      "loss 344.40960693359375\n",
      "loss 467.4036865234375\n",
      "loss 327.85015869140625\n",
      "loss 369.182861328125\n",
      "loss 487.389892578125\n",
      "loss 522.0040893554688\n",
      "loss 334.8711242675781\n",
      "loss 456.7847900390625\n",
      "loss 360.6114501953125\n",
      "loss 387.4977111816406\n",
      "loss 410.76239013671875\n",
      "loss 442.8099060058594\n",
      "loss 263.2354736328125\n",
      "loss 251.29457092285156\n",
      "loss 264.8446044921875\n",
      "loss 391.86529541015625\n",
      "loss 313.0044250488281\n",
      "loss 366.352783203125\n",
      "loss 399.079345703125\n",
      "loss 472.6219787597656\n",
      "loss 335.6572570800781\n",
      "loss 272.415283203125\n",
      "loss 257.12945556640625\n",
      "loss 467.0471496582031\n",
      "loss 441.4945373535156\n",
      "loss 752.496337890625\n",
      "loss 472.3043518066406\n",
      "loss 320.92218017578125\n",
      "loss 327.1609802246094\n",
      "loss 454.21368408203125\n",
      "loss 433.3244323730469\n",
      "loss 399.2468566894531\n",
      "loss 348.736572265625\n",
      "loss 564.527099609375\n",
      "loss 375.739013671875\n",
      "loss 377.9367370605469\n",
      "loss 461.8285827636719\n",
      "loss 352.7391357421875\n",
      "loss 339.02630615234375\n",
      "loss 353.01373291015625\n",
      "loss 300.9042053222656\n",
      "loss 314.26556396484375\n",
      "loss 391.64422607421875\n",
      "loss 315.66876220703125\n",
      "loss 459.68572998046875\n",
      "loss 239.72763061523438\n",
      "loss 447.50677490234375\n",
      "loss 370.3363952636719\n",
      "loss 317.0235595703125\n",
      "loss 302.5234069824219\n",
      "loss 314.966552734375\n",
      "loss 328.92230224609375\n",
      "loss 366.7177734375\n",
      "loss 392.8029479980469\n",
      "loss 331.5658264160156\n",
      "loss 482.6263427734375\n",
      "loss 358.2873229980469\n",
      "loss 356.7973327636719\n",
      "loss 385.7629089355469\n",
      "loss 321.58697509765625\n",
      "loss 265.9578552246094\n",
      "loss 285.4134521484375\n",
      "loss 323.3123779296875\n",
      "loss 504.4093017578125\n",
      "loss 315.7737121582031\n",
      "loss 420.41943359375\n",
      "loss 365.6543273925781\n",
      "loss 307.1946716308594\n",
      "loss 419.3329772949219\n",
      "loss 345.3524475097656\n",
      "loss 317.4337463378906\n",
      "loss 403.69964599609375\n",
      "loss 328.90960693359375\n",
      "loss 317.36871337890625\n",
      "loss 311.0054626464844\n",
      "loss 295.1434020996094\n",
      "loss 743.1138916015625\n",
      "loss 332.3206787109375\n",
      "loss 260.5783386230469\n",
      "loss 463.1578063964844\n",
      "loss 296.2295227050781\n",
      "loss 328.62554931640625\n",
      "loss 404.9931335449219\n",
      "loss 964.51513671875\n",
      "loss 287.9151306152344\n",
      "loss 323.0184020996094\n",
      "loss 548.0477294921875\n",
      "loss 326.12274169921875\n",
      "loss 364.4474792480469\n",
      "loss 340.0119323730469\n",
      "loss 595.9566650390625\n",
      "loss 289.466796875\n",
      "loss 391.2745361328125\n",
      "loss 463.3329162597656\n",
      "loss 448.69732666015625\n",
      "loss 382.14923095703125\n",
      "loss 463.8962097167969\n",
      "loss 494.2401428222656\n",
      "loss 307.2985534667969\n",
      "loss 497.08551025390625\n",
      "loss 377.3331298828125\n",
      "loss 357.36041259765625\n",
      "loss 281.6914978027344\n",
      "loss 357.4124450683594\n",
      "loss 428.0572814941406\n",
      "loss 342.9447326660156\n",
      "loss 431.2390441894531\n",
      "loss 334.24652099609375\n",
      "loss 409.236572265625\n",
      "loss 356.9482727050781\n",
      "loss 362.28125\n",
      "loss 395.6604309082031\n",
      "loss 454.55316162109375\n",
      "loss 456.42266845703125\n",
      "loss 469.69464111328125\n",
      "loss 298.06512451171875\n",
      "loss 331.38470458984375\n",
      "loss 465.0976867675781\n",
      "loss 405.5468444824219\n",
      "loss 460.18878173828125\n",
      "loss 397.3229675292969\n",
      "loss 396.6529541015625\n",
      "loss 512.3991088867188\n",
      "loss 723.2941284179688\n",
      "loss 257.6555480957031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 357.01513671875\n",
      "loss 391.74322509765625\n",
      "loss 306.82537841796875\n",
      "loss 543.410400390625\n",
      "loss 348.0943603515625\n",
      "loss 868.400634765625\n",
      "loss 311.603515625\n",
      "loss 328.1185302734375\n",
      "loss 288.61077880859375\n",
      "loss 350.6279602050781\n",
      "loss 501.6229248046875\n",
      "loss 330.0567626953125\n",
      "loss 475.1842041015625\n",
      "loss 406.4109191894531\n",
      "loss 316.1250915527344\n",
      "loss 756.8906860351562\n",
      "loss 320.4937744140625\n",
      "loss 425.35552978515625\n",
      "loss 348.95294189453125\n",
      "loss 389.7572021484375\n",
      "loss 342.56146240234375\n",
      "loss 330.9590759277344\n",
      "loss 352.36724853515625\n",
      "loss 380.516357421875\n",
      "loss 388.98504638671875\n",
      "loss 600.2908935546875\n",
      "loss 372.12078857421875\n",
      "loss 321.8591003417969\n",
      "loss 321.74945068359375\n",
      "loss 334.359375\n",
      "loss 730.710693359375\n",
      "loss 480.5279541015625\n",
      "loss 422.4017333984375\n",
      "loss 284.6346740722656\n",
      "loss 451.3453369140625\n",
      "loss 384.87200927734375\n",
      "loss 729.07470703125\n",
      "loss 408.7728271484375\n",
      "loss 423.3243408203125\n",
      "loss 458.825439453125\n",
      "loss 305.5806884765625\n",
      "loss 421.7923278808594\n",
      "loss 417.21661376953125\n",
      "loss 372.1180419921875\n",
      "loss 320.1844482421875\n",
      "loss 351.8230285644531\n",
      "loss 365.79815673828125\n",
      "loss 347.9988708496094\n",
      "loss 443.38153076171875\n",
      "loss 298.20709228515625\n",
      "loss 579.8778076171875\n",
      "loss 650.862548828125\n",
      "loss 272.6307678222656\n",
      "loss 480.4901123046875\n",
      "loss 287.7627868652344\n",
      "loss 400.3565368652344\n",
      "loss 348.5139465332031\n",
      "loss 717.3739624023438\n",
      "loss 337.49322509765625\n",
      "loss 182.44378662109375\n",
      "loss 481.10687255859375\n",
      "loss 308.91546630859375\n",
      "loss 332.22161865234375\n",
      "loss 415.91912841796875\n",
      "loss 421.45654296875\n",
      "loss 503.3722229003906\n",
      "loss 471.20343017578125\n",
      "loss 520.7086181640625\n",
      "loss 376.6776428222656\n",
      "loss 289.24700927734375\n",
      "loss 398.12939453125\n",
      "loss 318.8692626953125\n",
      "loss 309.76702880859375\n",
      "loss 312.04278564453125\n",
      "loss 557.0759887695312\n",
      "loss 244.75975036621094\n",
      "loss 273.6501159667969\n",
      "loss 405.1153564453125\n",
      "loss 245.53883361816406\n",
      "loss 782.6187744140625\n",
      "loss 355.943359375\n",
      "loss 374.10028076171875\n",
      "loss 884.5875244140625\n",
      "loss 570.4575805664062\n",
      "loss 276.3380432128906\n",
      "loss 397.10601806640625\n",
      "loss 367.102783203125\n",
      "loss 453.80029296875\n",
      "loss 370.82318115234375\n",
      "loss 413.5263366699219\n",
      "loss 297.30712890625\n",
      "loss 349.7032470703125\n",
      "loss 349.44097900390625\n",
      "loss 394.3634948730469\n",
      "loss 435.13995361328125\n",
      "loss 325.2649841308594\n",
      "loss 314.59613037109375\n",
      "loss 347.09503173828125\n",
      "loss 731.0980834960938\n",
      "loss 366.1774597167969\n",
      "loss 490.2935791015625\n",
      "loss 627.7181396484375\n",
      "loss 348.90093994140625\n",
      "loss 310.3106384277344\n",
      "loss 373.0309753417969\n",
      "loss 420.3016357421875\n",
      "loss 350.8598327636719\n",
      "loss 506.96038818359375\n",
      "loss 360.3827819824219\n",
      "loss 307.5635986328125\n",
      "loss 345.54937744140625\n",
      "loss 568.6231079101562\n",
      "loss 356.621826171875\n",
      "loss 374.4700927734375\n",
      "loss 397.4978942871094\n",
      "loss 333.6943359375\n",
      "loss 342.18194580078125\n",
      "loss 619.015380859375\n",
      "loss 372.8377685546875\n",
      "loss 334.8711853027344\n",
      "loss 409.3111267089844\n",
      "loss 443.47015380859375\n",
      "loss 390.80364990234375\n",
      "loss 363.4981689453125\n",
      "loss 284.93975830078125\n",
      "loss 369.8886413574219\n",
      "loss 312.0298767089844\n",
      "loss 643.0325927734375\n",
      "loss 281.3646545410156\n",
      "loss 302.3026123046875\n",
      "loss 573.8750610351562\n",
      "loss 298.6172180175781\n",
      "loss 524.8402099609375\n",
      "loss 762.5038452148438\n",
      "loss 318.7550354003906\n",
      "loss 673.8681640625\n",
      "loss 262.8791198730469\n",
      "loss 340.4659423828125\n",
      "loss 426.8914489746094\n",
      "loss 371.93011474609375\n",
      "loss 454.39581298828125\n",
      "loss 681.7845458984375\n",
      "loss 369.88848876953125\n",
      "loss 358.7069091796875\n",
      "loss 436.9810791015625\n",
      "loss 285.21429443359375\n",
      "loss 324.76611328125\n",
      "loss 370.9039306640625\n",
      "loss 367.6795654296875\n",
      "loss 404.4020690917969\n",
      "loss 333.00982666015625\n",
      "loss 257.5146179199219\n",
      "loss 249.881591796875\n",
      "loss 549.7105712890625\n",
      "loss 403.66796875\n",
      "loss 454.2376403808594\n",
      "loss 340.22906494140625\n",
      "loss 267.55950927734375\n",
      "loss 270.3594055175781\n",
      "loss 462.62701416015625\n",
      "loss 688.9892578125\n",
      "loss 918.119873046875\n",
      "loss 309.74261474609375\n",
      "loss 316.8834533691406\n",
      "loss 774.3242797851562\n",
      "loss 307.6451721191406\n",
      "loss 364.5441589355469\n",
      "loss 394.1897277832031\n",
      "loss 451.14910888671875\n",
      "loss 425.1385192871094\n",
      "loss 518.4194946289062\n",
      "loss 337.32269287109375\n",
      "loss 557.2278442382812\n",
      "loss 437.2623596191406\n",
      "loss 435.9888916015625\n",
      "loss 469.371826171875\n",
      "loss 454.8395080566406\n",
      "loss 335.3193664550781\n",
      "loss 451.6451110839844\n",
      "loss 405.2176818847656\n",
      "loss 462.53436279296875\n",
      "loss 334.0977478027344\n",
      "loss 370.6158447265625\n",
      "loss 367.2057189941406\n",
      "loss 283.02264404296875\n",
      "loss 428.9356994628906\n",
      "loss 524.1966552734375\n",
      "loss 303.7363586425781\n",
      "loss 424.51837158203125\n",
      "loss 251.31484985351562\n",
      "loss 307.45611572265625\n",
      "loss 401.2198791503906\n",
      "loss 641.0728759765625\n",
      "loss 324.0008239746094\n",
      "loss 1113.6524658203125\n",
      "loss 352.4107666015625\n",
      "loss 304.2762451171875\n",
      "loss 225.45523071289062\n",
      "loss 377.3619079589844\n",
      "loss 442.37762451171875\n",
      "loss 406.97711181640625\n",
      "loss 404.373046875\n",
      "loss 552.7396850585938\n",
      "loss 438.7660217285156\n",
      "loss 309.4729919433594\n",
      "loss 662.4071655273438\n",
      "loss 484.0867004394531\n",
      "loss 250.78643798828125\n",
      "loss 397.3542175292969\n",
      "loss 448.23309326171875\n",
      "loss 256.4970397949219\n",
      "loss 371.9373779296875\n",
      "loss 414.8995361328125\n",
      "loss 391.76904296875\n",
      "loss 280.82354736328125\n",
      "loss 323.8722229003906\n",
      "loss 356.2214050292969\n",
      "loss 251.74610900878906\n",
      "loss 394.64190673828125\n",
      "loss 509.0034484863281\n",
      "loss 282.35638427734375\n",
      "loss 365.6635437011719\n",
      "loss 381.64300537109375\n",
      "loss 494.6649475097656\n",
      "loss 297.68292236328125\n",
      "loss 355.7690734863281\n",
      "loss 373.0444641113281\n",
      "loss 411.5824890136719\n",
      "loss 718.8851318359375\n",
      "loss 456.46893310546875\n",
      "loss 230.3661346435547\n",
      "loss 361.5292663574219\n",
      "loss 377.6832275390625\n",
      "loss 329.85906982421875\n",
      "loss 635.6241455078125\n",
      "loss 372.8703308105469\n",
      "loss 335.6845703125\n",
      "loss 361.8795166015625\n",
      "loss 409.66595458984375\n",
      "loss 297.8882141113281\n",
      "loss 364.5196838378906\n",
      "loss 437.80706787109375\n",
      "loss 443.19293212890625\n",
      "loss 408.7518310546875\n",
      "loss 284.9046936035156\n",
      "loss 458.69940185546875\n",
      "loss 541.0494384765625\n",
      "loss 289.0164489746094\n",
      "loss 425.14410400390625\n",
      "loss 310.25701904296875\n",
      "loss 362.19329833984375\n",
      "loss 417.0538024902344\n",
      "loss 432.7277526855469\n",
      "loss 385.4827880859375\n",
      "loss 657.0300903320312\n",
      "loss 332.268798828125\n",
      "loss 381.86688232421875\n",
      "loss 352.36883544921875\n",
      "loss 438.8438720703125\n",
      "loss 625.0120849609375\n",
      "loss 513.7382202148438\n",
      "loss 293.32257080078125\n",
      "loss 380.6838684082031\n",
      "loss 382.3437194824219\n",
      "loss 533.25830078125\n",
      "loss 374.97662353515625\n",
      "loss 283.2155456542969\n",
      "loss 362.9000549316406\n",
      "loss 490.51434326171875\n",
      "loss 411.64263916015625\n",
      "loss 384.2442932128906\n",
      "loss 220.0800323486328\n",
      "loss 347.90667724609375\n",
      "loss 354.40069580078125\n",
      "loss 381.3665771484375\n",
      "loss 403.6779479980469\n",
      "loss 604.26611328125\n",
      "loss 320.2164611816406\n",
      "loss 343.6956787109375\n",
      "loss 428.0726013183594\n",
      "loss 543.4818115234375\n",
      "loss 800.349609375\n",
      "loss 360.93096923828125\n",
      "loss 290.2682800292969\n",
      "loss 404.2670593261719\n",
      "loss 363.0254821777344\n",
      "loss 209.74839782714844\n",
      "loss 328.4500732421875\n",
      "loss 276.24578857421875\n",
      "loss 359.3516845703125\n",
      "loss 437.9964904785156\n",
      "loss 415.27166748046875\n",
      "loss 331.6899719238281\n",
      "loss 459.96453857421875\n",
      "loss 334.8826904296875\n",
      "loss 341.71295166015625\n",
      "loss 324.62359619140625\n",
      "loss 360.9797668457031\n",
      "loss 333.45928955078125\n",
      "loss 346.01739501953125\n",
      "loss 376.5703430175781\n",
      "loss 661.3988647460938\n",
      "loss 454.25738525390625\n",
      "loss 317.7275085449219\n",
      "loss 753.1160888671875\n",
      "loss 559.4522705078125\n",
      "loss 630.8858032226562\n",
      "loss 288.88238525390625\n",
      "loss 381.4669494628906\n",
      "loss 392.1573181152344\n",
      "loss 357.39599609375\n",
      "loss 395.471435546875\n",
      "loss 383.74249267578125\n",
      "loss 208.52386474609375\n",
      "loss 418.6033630371094\n",
      "loss 392.6876220703125\n",
      "loss 411.7437438964844\n",
      "loss 319.4233093261719\n",
      "loss 380.22576904296875\n",
      "loss 270.8272705078125\n",
      "loss 364.41888427734375\n",
      "loss 249.6136474609375\n",
      "loss 321.8232421875\n",
      "loss 450.20147705078125\n",
      "loss 373.2969970703125\n",
      "loss 375.9678649902344\n",
      "loss 418.6344909667969\n",
      "loss 401.7101745605469\n",
      "loss 393.9606628417969\n",
      "loss 386.87353515625\n",
      "loss 288.31866455078125\n",
      "loss 464.284912109375\n",
      "loss 323.0273742675781\n",
      "loss 458.4322204589844\n",
      "loss 299.81060791015625\n",
      "loss 259.505126953125\n",
      "loss 417.8669738769531\n",
      "loss 284.4140625\n",
      "loss 270.01416015625\n",
      "loss 361.33441162109375\n",
      "loss 648.74951171875\n",
      "loss 326.4073791503906\n",
      "loss 766.1419677734375\n",
      "loss 410.0259094238281\n",
      "loss 351.57257080078125\n",
      "loss 431.4672546386719\n",
      "loss 283.0242614746094\n",
      "loss 388.2803649902344\n",
      "loss 532.5283813476562\n",
      "loss 437.2318115234375\n",
      "loss 430.1866455078125\n",
      "loss 295.9610290527344\n",
      "loss 487.83648681640625\n",
      "loss 416.86602783203125\n",
      "loss 373.1756286621094\n",
      "loss 591.7747802734375\n",
      "loss 402.7559814453125\n",
      "loss 349.85369873046875\n",
      "loss 337.1656799316406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 494.9483642578125\n",
      "loss 366.32464599609375\n",
      "loss 459.0738525390625\n",
      "loss 337.6313781738281\n",
      "loss 363.2275390625\n",
      "loss 551.3720092773438\n",
      "loss 497.9190368652344\n",
      "loss 553.4082641601562\n",
      "loss 323.12615966796875\n",
      "loss 497.3868408203125\n",
      "loss 446.4252624511719\n",
      "loss 362.6329650878906\n",
      "loss 350.0099792480469\n",
      "loss 442.7615661621094\n",
      "loss 279.1993408203125\n",
      "loss 687.7481079101562\n",
      "loss 378.2934875488281\n",
      "loss 524.8873901367188\n",
      "loss 369.2953796386719\n",
      "loss 374.23248291015625\n",
      "loss 278.6727294921875\n",
      "loss 658.1229248046875\n",
      "loss 467.3301696777344\n",
      "loss 598.4109497070312\n",
      "loss 255.613525390625\n",
      "loss 243.1964874267578\n",
      "loss 526.8643188476562\n",
      "loss 406.4610595703125\n",
      "loss 504.800537109375\n",
      "loss 384.687255859375\n",
      "loss 403.748291015625\n",
      "loss 295.1748046875\n",
      "loss 419.291259765625\n",
      "loss 456.82684326171875\n",
      "loss 558.7097778320312\n",
      "loss 380.2127990722656\n",
      "loss 409.1585693359375\n",
      "loss 448.1282958984375\n",
      "loss 561.64306640625\n",
      "loss 344.5418395996094\n",
      "loss 473.8985595703125\n",
      "loss 438.6227722167969\n",
      "loss 326.906982421875\n",
      "loss 350.2979736328125\n",
      "loss 420.3946533203125\n",
      "loss 372.6969909667969\n",
      "loss 317.0409240722656\n",
      "loss 395.8553161621094\n",
      "loss 414.2645263671875\n",
      "loss 271.6995849609375\n",
      "loss 368.5010681152344\n",
      "loss 347.7369384765625\n",
      "loss 410.8731994628906\n",
      "loss 446.7252197265625\n",
      "loss 383.3849792480469\n",
      "loss 587.094482421875\n",
      "loss 292.8258056640625\n",
      "loss 368.2054138183594\n",
      "loss 533.6045532226562\n",
      "loss 325.7309875488281\n",
      "loss 370.2464599609375\n",
      "loss 425.0905456542969\n",
      "loss 328.685302734375\n",
      "loss 372.2049865722656\n",
      "loss 507.5862731933594\n",
      "loss 392.1917724609375\n",
      "loss 187.80975341796875\n",
      "loss 399.0975036621094\n",
      "loss 582.7470092773438\n",
      "loss 252.32852172851562\n",
      "loss 484.4262390136719\n",
      "loss 390.49066162109375\n",
      "loss 308.7821960449219\n",
      "loss 358.0985107421875\n",
      "loss 305.8355407714844\n",
      "loss 484.26312255859375\n",
      "loss 357.75604248046875\n",
      "loss 416.7294006347656\n",
      "loss 311.94183349609375\n",
      "loss 379.074462890625\n",
      "loss 326.9881286621094\n",
      "loss 535.24267578125\n",
      "loss 379.0438232421875\n",
      "loss 613.9920654296875\n",
      "loss 334.6571960449219\n",
      "loss 271.8440246582031\n",
      "loss 259.4277038574219\n",
      "loss 343.04925537109375\n",
      "loss 264.98028564453125\n",
      "loss 393.59173583984375\n",
      "loss 412.9686279296875\n",
      "loss 422.9702453613281\n",
      "loss 598.4962158203125\n",
      "loss 617.1131591796875\n",
      "loss 459.65911865234375\n",
      "loss 331.4554138183594\n",
      "loss 472.8355712890625\n",
      "loss 465.3306884765625\n",
      "loss 450.58648681640625\n",
      "loss 673.5748291015625\n",
      "loss 243.45127868652344\n",
      "loss 422.4701843261719\n",
      "loss 286.2353515625\n",
      "loss 330.5967102050781\n",
      "loss 356.6819152832031\n",
      "loss 414.46661376953125\n",
      "loss 371.4891662597656\n",
      "loss 380.19482421875\n",
      "loss 328.86712646484375\n",
      "loss 292.0757751464844\n",
      "loss 421.7226257324219\n",
      "loss 430.5964050292969\n",
      "loss 385.4279479980469\n",
      "loss 458.0191345214844\n",
      "loss 400.36944580078125\n",
      "loss 382.6054992675781\n",
      "loss 331.0718688964844\n",
      "loss 374.6062316894531\n",
      "loss 453.01422119140625\n",
      "loss 465.2846374511719\n",
      "loss 401.87005615234375\n",
      "loss 1016.8807373046875\n",
      "loss 394.0816345214844\n",
      "loss 492.5784912109375\n",
      "loss 466.39971923828125\n",
      "loss 264.7056579589844\n",
      "loss 431.12359619140625\n",
      "loss 429.95465087890625\n",
      "loss 373.56365966796875\n",
      "loss 575.1665649414062\n",
      "loss 477.62493896484375\n",
      "loss 403.5868835449219\n",
      "loss 356.05853271484375\n",
      "loss 324.55499267578125\n",
      "loss 351.6758117675781\n",
      "loss 350.22021484375\n",
      "loss 439.62164306640625\n",
      "loss 302.64501953125\n",
      "loss 467.9261169433594\n",
      "loss 305.6961669921875\n",
      "loss 297.4122619628906\n",
      "loss 395.31683349609375\n",
      "loss 426.4245300292969\n",
      "loss 343.1815490722656\n",
      "loss 335.0189514160156\n",
      "loss 375.0189208984375\n",
      "loss 279.31097412109375\n",
      "loss 461.2496337890625\n",
      "loss 255.16819763183594\n",
      "loss 298.8560791015625\n",
      "loss 382.1349182128906\n",
      "loss 564.8310546875\n",
      "loss 305.76617431640625\n",
      "loss 538.1841430664062\n",
      "loss 990.9010620117188\n",
      "loss 372.79266357421875\n",
      "loss 486.26177978515625\n",
      "loss 413.8050231933594\n",
      "loss 311.40484619140625\n",
      "loss 339.8158874511719\n",
      "loss 270.5684509277344\n",
      "loss 270.3079528808594\n",
      "loss 264.6396789550781\n",
      "loss 359.34747314453125\n",
      "loss 279.3836364746094\n",
      "loss 499.08447265625\n",
      "loss 450.749755859375\n",
      "loss 403.153564453125\n",
      "loss 343.6327819824219\n",
      "loss 396.8650817871094\n",
      "loss 359.0206298828125\n",
      "loss 265.9258728027344\n",
      "loss 514.1181640625\n",
      "loss 332.6783752441406\n",
      "loss 348.50634765625\n",
      "loss 335.6970520019531\n",
      "loss 350.3167724609375\n",
      "loss 432.7519226074219\n",
      "loss 436.1506042480469\n",
      "loss 423.5843811035156\n",
      "loss 396.4076232910156\n",
      "loss 557.9530639648438\n",
      "loss 366.23492431640625\n",
      "loss 312.2343444824219\n",
      "loss 375.17144775390625\n",
      "loss 507.2618408203125\n",
      "loss 403.32208251953125\n",
      "loss 316.4720458984375\n",
      "loss 415.814697265625\n",
      "loss 395.6747131347656\n",
      "loss 1019.539794921875\n",
      "loss 1048.4620361328125\n",
      "loss 300.81268310546875\n",
      "loss 271.71661376953125\n",
      "loss 187.27462768554688\n",
      "loss 604.377197265625\n",
      "loss 482.0151062011719\n",
      "loss 529.0299682617188\n",
      "loss 335.13055419921875\n",
      "loss 382.05755615234375\n",
      "loss 291.2658386230469\n",
      "loss 372.1886291503906\n",
      "loss 515.126953125\n",
      "loss 573.2754516601562\n",
      "loss 299.5766296386719\n",
      "loss 363.21527099609375\n",
      "loss 380.7413024902344\n",
      "loss 389.2947692871094\n",
      "loss 270.4516906738281\n",
      "loss 397.2261962890625\n",
      "loss 883.1129150390625\n",
      "loss 288.51824951171875\n",
      "loss 522.469970703125\n",
      "loss 317.9804992675781\n",
      "loss 275.0301513671875\n",
      "loss 261.3966369628906\n",
      "loss 351.49755859375\n",
      "loss 270.0942077636719\n",
      "loss 319.0695495605469\n",
      "loss 423.7605285644531\n",
      "loss 366.7987976074219\n",
      "loss 438.1395568847656\n",
      "loss 326.4041748046875\n",
      "loss 317.0242919921875\n",
      "loss 323.7438049316406\n",
      "loss 283.82537841796875\n",
      "loss 243.27197265625\n",
      "loss 397.05450439453125\n",
      "loss 619.9036865234375\n",
      "loss 440.21905517578125\n",
      "loss 571.105224609375\n",
      "loss 311.6812744140625\n",
      "loss 337.9090576171875\n",
      "loss 340.7803955078125\n",
      "loss 456.3778381347656\n",
      "loss 220.78346252441406\n",
      "loss 437.401611328125\n",
      "loss 458.4637756347656\n",
      "loss 277.3079833984375\n",
      "loss 285.7069091796875\n",
      "loss 536.3919677734375\n",
      "loss 533.7286987304688\n",
      "loss 287.68353271484375\n",
      "loss 375.78131103515625\n",
      "loss 403.88946533203125\n",
      "loss 415.4619140625\n",
      "loss 876.3046264648438\n",
      "loss 563.4967041015625\n",
      "loss 503.5421447753906\n",
      "loss 467.283447265625\n",
      "loss 503.1007080078125\n",
      "loss 321.57525634765625\n",
      "loss 404.47174072265625\n",
      "loss 498.6354675292969\n",
      "loss 668.4009399414062\n",
      "loss 390.513427734375\n",
      "loss 481.5013732910156\n",
      "loss 316.99530029296875\n",
      "loss 377.2645568847656\n",
      "loss 373.58551025390625\n",
      "loss 326.8917236328125\n",
      "loss 319.72161865234375\n",
      "loss 338.4252624511719\n",
      "loss 354.6255187988281\n",
      "loss 484.37744140625\n",
      "loss 362.2535705566406\n",
      "loss 453.4620056152344\n",
      "loss 385.58636474609375\n",
      "loss 398.37939453125\n",
      "loss 484.6060791015625\n",
      "loss 483.3311462402344\n",
      "loss 255.53997802734375\n",
      "loss 528.2555541992188\n",
      "loss 412.0766296386719\n",
      "loss 298.4314270019531\n",
      "loss 397.4209899902344\n",
      "loss 786.8688354492188\n",
      "loss 484.3562316894531\n",
      "loss 441.73675537109375\n",
      "loss 416.3191223144531\n",
      "loss 662.096435546875\n",
      "loss 346.6986389160156\n",
      "loss 293.48724365234375\n",
      "loss 556.8530883789062\n",
      "loss 764.5103149414062\n",
      "loss 337.3650817871094\n",
      "loss 431.05523681640625\n",
      "loss 456.4425048828125\n",
      "loss 409.3975524902344\n",
      "loss 387.56610107421875\n",
      "loss 438.2796630859375\n",
      "loss 286.39764404296875\n",
      "loss 761.560546875\n",
      "loss 513.7498779296875\n",
      "loss 509.44537353515625\n",
      "loss 445.75634765625\n",
      "loss 435.5990905761719\n",
      "loss 277.50445556640625\n",
      "loss 317.71514892578125\n",
      "loss 499.04931640625\n",
      "loss 443.5555114746094\n",
      "loss 513.6661987304688\n",
      "loss 387.2369689941406\n",
      "loss 272.3054504394531\n",
      "loss 357.7144775390625\n",
      "loss 334.072265625\n",
      "loss 356.4925537109375\n",
      "loss 434.0605773925781\n",
      "loss 403.20806884765625\n",
      "loss 292.3351135253906\n",
      "loss 374.7181701660156\n",
      "loss 483.42022705078125\n",
      "loss 307.76983642578125\n",
      "loss 330.3597412109375\n",
      "loss 651.8892211914062\n",
      "loss 488.0364074707031\n",
      "loss 307.55657958984375\n",
      "loss 449.30181884765625\n",
      "loss 425.34906005859375\n",
      "loss 437.3706359863281\n",
      "loss 336.37481689453125\n",
      "loss 408.01605224609375\n",
      "loss 489.9122314453125\n",
      "loss 935.0169677734375\n",
      "loss 336.2533264160156\n",
      "loss 444.1717529296875\n",
      "loss 580.598388671875\n",
      "loss 284.4264221191406\n",
      "loss 315.2937927246094\n",
      "loss 276.4090576171875\n",
      "loss 306.8429260253906\n",
      "loss 312.3719787597656\n",
      "loss 745.1624755859375\n",
      "loss 524.1853637695312\n",
      "loss 512.1643676757812\n",
      "loss 557.7501220703125\n",
      "loss 386.1752624511719\n",
      "loss 557.5386962890625\n",
      "loss 447.7793884277344\n",
      "loss 337.0980529785156\n",
      "loss 255.69381713867188\n",
      "loss 358.901123046875\n",
      "loss 410.1262512207031\n",
      "loss 367.74310302734375\n",
      "loss 263.7908630371094\n",
      "loss 495.87628173828125\n",
      "loss 585.390625\n",
      "loss 679.8485717773438\n",
      "loss 401.7465515136719\n",
      "loss 304.5709228515625\n",
      "loss 404.09246826171875\n",
      "loss 327.2221374511719\n",
      "loss 340.9707336425781\n",
      "loss 255.7151641845703\n",
      "loss 432.5113220214844\n",
      "loss 529.52197265625\n",
      "loss 750.3895874023438\n",
      "loss 400.8259582519531\n",
      "loss 378.39385986328125\n",
      "loss 569.8773803710938\n",
      "loss 375.3811340332031\n",
      "loss 315.71044921875\n",
      "loss 373.426513671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 347.0264587402344\n",
      "loss 341.4560241699219\n",
      "loss 354.5184631347656\n",
      "loss 439.3745422363281\n",
      "loss 357.8902587890625\n",
      "loss 623.09423828125\n",
      "loss 337.414306640625\n",
      "loss 387.25347900390625\n",
      "loss 383.51019287109375\n",
      "loss 297.2076110839844\n",
      "loss 297.0413513183594\n",
      "loss 438.51666259765625\n",
      "loss 578.4052734375\n",
      "loss 423.39495849609375\n",
      "loss 319.8533935546875\n",
      "loss 291.3834228515625\n",
      "loss 456.5464782714844\n",
      "loss 401.3031311035156\n",
      "loss 426.40386962890625\n",
      "loss 311.4775390625\n",
      "loss 236.1425323486328\n",
      "loss 275.5554504394531\n",
      "loss 492.6764831542969\n",
      "loss 337.18670654296875\n",
      "loss 492.80755615234375\n",
      "loss 349.95611572265625\n",
      "loss 297.46563720703125\n",
      "loss 438.1418151855469\n",
      "loss 354.025390625\n",
      "loss 379.6389465332031\n",
      "loss 362.7607116699219\n",
      "loss 584.7579956054688\n",
      "loss 423.33746337890625\n",
      "loss 324.8386535644531\n",
      "loss 408.5301208496094\n",
      "loss 276.087646484375\n",
      "loss 412.93365478515625\n",
      "loss 379.0496520996094\n",
      "loss 434.0029296875\n",
      "loss 338.8439636230469\n",
      "loss 418.1705322265625\n",
      "loss 346.8443908691406\n",
      "loss 331.2395935058594\n",
      "loss 274.4010925292969\n",
      "loss 381.2580261230469\n",
      "loss 432.411865234375\n",
      "loss 267.4810791015625\n",
      "loss 410.60028076171875\n",
      "loss 520.0433349609375\n",
      "loss 437.4551086425781\n",
      "loss 425.7508850097656\n",
      "loss 453.18133544921875\n",
      "loss 784.09228515625\n",
      "loss 308.09686279296875\n",
      "loss 222.041259765625\n",
      "loss 544.372802734375\n",
      "loss 212.45596313476562\n",
      "loss 406.07781982421875\n",
      "loss 367.4100646972656\n",
      "loss 933.2247924804688\n",
      "loss 328.4259948730469\n",
      "loss 538.1063842773438\n",
      "loss 434.5002136230469\n",
      "loss 297.1969299316406\n",
      "loss 421.6772766113281\n",
      "loss 372.21661376953125\n",
      "loss 381.74603271484375\n",
      "loss 376.4024658203125\n",
      "loss 519.4352416992188\n",
      "loss 327.88836669921875\n",
      "loss 517.6956787109375\n",
      "loss 424.6286926269531\n",
      "loss 529.35986328125\n",
      "loss 1375.552734375\n",
      "loss 523.4710083007812\n",
      "loss 708.5325317382812\n",
      "loss 378.52362060546875\n",
      "loss 367.97637939453125\n",
      "loss 270.78399658203125\n",
      "loss 591.3025512695312\n",
      "loss 542.25\n",
      "loss 519.321533203125\n",
      "loss 293.1548767089844\n",
      "loss 372.8477478027344\n",
      "loss 324.99395751953125\n",
      "loss 305.0020446777344\n",
      "loss 368.183837890625\n",
      "loss 259.8768310546875\n",
      "loss 381.50604248046875\n",
      "loss 568.8756103515625\n",
      "loss 348.8326416015625\n",
      "loss 495.9294738769531\n",
      "loss 446.83685302734375\n",
      "loss 390.5561218261719\n",
      "loss 378.5679626464844\n",
      "loss 372.9490661621094\n",
      "loss 698.767578125\n",
      "loss 1027.8182373046875\n",
      "loss 462.8026123046875\n",
      "loss 574.02001953125\n",
      "loss 287.9084167480469\n",
      "loss 349.7847900390625\n",
      "loss 528.665771484375\n",
      "loss 390.9844970703125\n",
      "loss 866.7549438476562\n",
      "loss 424.45123291015625\n",
      "loss 432.1454162597656\n",
      "loss 428.6824035644531\n",
      "loss 518.0348510742188\n",
      "loss 412.6005554199219\n",
      "loss 309.12860107421875\n",
      "loss 283.8294372558594\n",
      "loss 457.6278381347656\n",
      "loss 354.361572265625\n",
      "loss 288.39508056640625\n",
      "loss 301.92474365234375\n",
      "loss 404.214111328125\n",
      "loss 514.0863037109375\n",
      "loss 426.8295593261719\n",
      "loss 471.07427978515625\n",
      "loss 385.9557189941406\n",
      "loss 246.57325744628906\n",
      "loss 306.49700927734375\n",
      "loss 390.8087158203125\n",
      "loss 356.2843322753906\n",
      "loss 463.69329833984375\n",
      "loss 305.25701904296875\n",
      "loss 317.91357421875\n",
      "loss 627.33935546875\n",
      "loss 376.6717224121094\n",
      "loss 384.8154602050781\n",
      "loss 557.3092041015625\n",
      "loss 363.8333740234375\n",
      "loss 390.2928161621094\n",
      "loss 470.1862487792969\n",
      "loss 463.57183837890625\n",
      "loss 307.1394958496094\n",
      "loss 408.4554443359375\n",
      "loss 346.4842529296875\n",
      "loss 526.340576171875\n",
      "loss 509.7044982910156\n",
      "loss 562.5020751953125\n",
      "loss 544.610107421875\n",
      "loss 438.1875305175781\n",
      "loss 305.9890441894531\n",
      "loss 247.17767333984375\n",
      "loss 556.4802856445312\n",
      "loss 435.04949951171875\n",
      "loss 501.99761962890625\n",
      "loss 292.4248352050781\n",
      "loss 502.323974609375\n",
      "loss 431.5119323730469\n",
      "loss 375.037109375\n",
      "loss 346.6771545410156\n",
      "loss 363.90289306640625\n",
      "loss 390.70428466796875\n",
      "loss 315.5747375488281\n",
      "loss 459.258056640625\n",
      "loss 271.4571533203125\n",
      "loss 710.7166137695312\n",
      "loss 407.8118896484375\n",
      "loss 406.9100341796875\n",
      "loss 284.28253173828125\n",
      "loss 452.35137939453125\n",
      "loss 350.6611328125\n",
      "loss 370.4685974121094\n",
      "loss 402.3895263671875\n",
      "loss 420.4583740234375\n",
      "loss 366.07073974609375\n",
      "loss 411.53936767578125\n",
      "loss 418.8876037597656\n",
      "loss 357.57373046875\n",
      "loss 376.31488037109375\n",
      "loss 388.8001708984375\n",
      "loss 432.41259765625\n",
      "loss 439.9057312011719\n",
      "loss 592.2501831054688\n",
      "loss 747.2622680664062\n",
      "loss 504.9398193359375\n",
      "loss 400.7890625\n",
      "loss 338.4017028808594\n",
      "loss 384.11810302734375\n",
      "loss 343.1168518066406\n",
      "loss 537.4330444335938\n",
      "loss 256.7486267089844\n",
      "loss 408.96136474609375\n",
      "loss 334.3243713378906\n",
      "loss 597.8945922851562\n",
      "loss 318.57781982421875\n",
      "loss 648.8890380859375\n",
      "loss 351.0609436035156\n",
      "loss 372.6142578125\n",
      "loss 477.306884765625\n",
      "loss 356.9520263671875\n",
      "loss 511.7373352050781\n",
      "loss 257.258544921875\n",
      "loss 322.2485656738281\n",
      "loss 351.63238525390625\n",
      "loss 336.2718811035156\n",
      "loss 494.1102294921875\n",
      "loss 372.25201416015625\n",
      "loss 340.42974853515625\n",
      "loss 277.807861328125\n",
      "loss 349.1140441894531\n",
      "loss 340.34002685546875\n",
      "loss 333.1552734375\n",
      "loss 360.3367004394531\n",
      "loss 323.7105712890625\n",
      "loss 487.16864013671875\n",
      "loss 382.040771484375\n",
      "loss 574.185791015625\n",
      "loss 379.9682312011719\n",
      "loss 398.31097412109375\n",
      "loss 447.1153869628906\n",
      "loss 446.4617614746094\n",
      "loss 350.56658935546875\n",
      "loss 323.79339599609375\n",
      "loss 321.9542236328125\n",
      "loss 290.7378234863281\n",
      "loss 304.96014404296875\n",
      "loss 459.3890075683594\n",
      "loss 366.954345703125\n",
      "loss 313.2154541015625\n",
      "loss 279.32281494140625\n",
      "loss 604.1661376953125\n",
      "loss 385.9920959472656\n",
      "loss 341.03125\n",
      "loss 338.97998046875\n",
      "loss 287.6549987792969\n",
      "loss 395.9900817871094\n",
      "loss 346.0712585449219\n",
      "loss 346.7384033203125\n",
      "loss 521.2012939453125\n",
      "loss 700.3462524414062\n",
      "loss 311.67535400390625\n",
      "loss 339.30902099609375\n",
      "loss 245.62796020507812\n",
      "loss 436.6524353027344\n",
      "loss 352.6405944824219\n",
      "loss 284.6200256347656\n",
      "loss 432.696044921875\n",
      "loss 274.5434265136719\n",
      "loss 309.751708984375\n",
      "loss 308.7760925292969\n",
      "loss 379.9666748046875\n",
      "loss 353.037109375\n",
      "loss 508.7357177734375\n",
      "loss 310.3193054199219\n",
      "loss 657.3778686523438\n",
      "loss 258.43109130859375\n",
      "loss 407.41802978515625\n",
      "loss 289.0608215332031\n",
      "loss 447.5534973144531\n",
      "loss 357.10888671875\n",
      "loss 439.28778076171875\n",
      "loss 326.1997985839844\n",
      "loss 318.6934814453125\n",
      "loss 248.44825744628906\n",
      "loss 574.185791015625\n",
      "loss 413.01873779296875\n",
      "loss 471.9425354003906\n",
      "loss 725.1477661132812\n",
      "loss 376.76611328125\n",
      "loss 480.7845764160156\n",
      "loss 514.0619506835938\n",
      "loss 344.6121520996094\n",
      "loss 285.3199157714844\n",
      "loss 321.2527160644531\n",
      "loss 442.1313781738281\n",
      "loss 396.6174621582031\n",
      "loss 444.5462341308594\n",
      "loss 280.85333251953125\n",
      "loss 326.2547912597656\n",
      "loss 446.67431640625\n",
      "loss 259.45367431640625\n",
      "loss 387.702392578125\n",
      "loss 360.64056396484375\n",
      "loss 486.9805603027344\n",
      "loss 402.6114807128906\n",
      "loss 482.8552551269531\n",
      "loss 470.8582458496094\n",
      "loss 325.8910217285156\n",
      "loss 340.7430419921875\n",
      "loss 340.71826171875\n",
      "loss 627.000732421875\n",
      "loss 506.32275390625\n",
      "loss 283.5094909667969\n",
      "loss 332.2448425292969\n",
      "loss 598.6744384765625\n",
      "loss 338.603515625\n",
      "loss 394.43212890625\n",
      "loss 446.407958984375\n",
      "loss 291.6466369628906\n",
      "loss 293.72027587890625\n",
      "loss 391.3320617675781\n",
      "loss 462.9802551269531\n",
      "loss 435.51312255859375\n",
      "loss 358.3381042480469\n",
      "loss 329.03314208984375\n",
      "loss 385.12396240234375\n",
      "loss 284.1379089355469\n",
      "loss 519.48046875\n",
      "loss 969.81982421875\n",
      "loss 375.6486511230469\n",
      "loss 294.9991149902344\n",
      "loss 457.16961669921875\n",
      "loss 600.3456420898438\n",
      "loss 338.16497802734375\n",
      "loss 597.1570434570312\n",
      "loss 716.94873046875\n",
      "loss 358.58477783203125\n",
      "loss 439.19775390625\n",
      "loss 546.9995727539062\n",
      "loss 376.00372314453125\n",
      "loss 280.29852294921875\n",
      "loss 302.17938232421875\n",
      "loss 574.3528442382812\n",
      "loss 444.7945861816406\n",
      "loss 427.7343444824219\n",
      "loss 332.077880859375\n",
      "loss 276.5747375488281\n",
      "loss 281.8011474609375\n",
      "loss 370.8798828125\n",
      "loss 310.3573913574219\n",
      "loss 561.0048828125\n",
      "loss 452.76385498046875\n",
      "loss 495.0643005371094\n",
      "loss 394.46142578125\n",
      "loss 499.62994384765625\n",
      "loss 397.35009765625\n",
      "loss 564.9232177734375\n",
      "loss 344.8674621582031\n",
      "loss 279.5294189453125\n",
      "loss 385.23846435546875\n",
      "loss 477.16021728515625\n",
      "loss 390.3466796875\n",
      "loss 469.79278564453125\n",
      "loss 514.8549194335938\n",
      "loss 389.3435974121094\n",
      "loss 356.6387023925781\n",
      "loss 216.02041625976562\n",
      "loss 261.36041259765625\n",
      "loss 507.7742614746094\n",
      "loss 285.85174560546875\n",
      "loss 666.3057250976562\n",
      "loss 684.1881103515625\n",
      "loss 398.10540771484375\n",
      "loss 447.99560546875\n",
      "loss 380.1499938964844\n",
      "loss 322.46405029296875\n",
      "loss 361.48406982421875\n",
      "loss 338.056640625\n",
      "loss 291.01312255859375\n",
      "loss 318.94244384765625\n",
      "loss 403.9769592285156\n",
      "loss 341.8157043457031\n",
      "loss 266.6002197265625\n",
      "loss 239.91342163085938\n",
      "loss 255.373291015625\n",
      "loss 306.1832275390625\n",
      "loss 330.9640808105469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 316.6721496582031\n",
      "loss 374.238037109375\n",
      "loss 432.13916015625\n",
      "loss 272.4308776855469\n",
      "loss 354.67498779296875\n",
      "loss 406.01507568359375\n",
      "loss 427.6387939453125\n",
      "loss 361.9469909667969\n",
      "loss 472.5588684082031\n",
      "loss 326.45703125\n",
      "loss 289.4038391113281\n",
      "loss 572.046142578125\n",
      "loss 208.7650604248047\n",
      "loss 303.90911865234375\n",
      "loss 399.4202880859375\n",
      "loss 302.3722229003906\n",
      "loss 403.9847717285156\n",
      "loss 436.00750732421875\n",
      "loss 399.3282165527344\n",
      "loss 356.9268493652344\n",
      "loss 494.8403625488281\n",
      "loss 303.871826171875\n",
      "loss 341.1860656738281\n",
      "loss 504.48089599609375\n",
      "loss 494.6145324707031\n",
      "loss 341.3919677734375\n",
      "loss 251.042724609375\n",
      "loss 315.5506286621094\n",
      "loss 399.81689453125\n",
      "loss 386.02276611328125\n",
      "loss 424.1636657714844\n",
      "loss 294.79248046875\n",
      "loss 413.41937255859375\n",
      "loss 314.8946228027344\n",
      "loss 294.6028137207031\n",
      "loss 472.398193359375\n",
      "loss 364.4947509765625\n",
      "loss 457.65240478515625\n",
      "loss 185.48269653320312\n",
      "loss 309.9646911621094\n",
      "loss 1106.358154296875\n",
      "loss 381.25152587890625\n",
      "loss 381.3868103027344\n",
      "loss 464.28448486328125\n",
      "loss 252.82601928710938\n",
      "loss 346.29644775390625\n",
      "loss 546.0283203125\n",
      "loss 420.15673828125\n",
      "loss 397.4466247558594\n",
      "loss 401.47406005859375\n",
      "loss 508.2431945800781\n",
      "loss 404.625244140625\n",
      "loss 327.79205322265625\n",
      "loss 368.8283996582031\n",
      "loss 334.2161560058594\n",
      "loss 560.58349609375\n",
      "loss 463.83685302734375\n",
      "loss 434.4864807128906\n",
      "loss 284.699462890625\n",
      "loss 427.9344787597656\n",
      "loss 400.19549560546875\n",
      "loss 507.9788513183594\n",
      "loss 360.9803161621094\n",
      "loss 289.1156005859375\n",
      "loss 417.95941162109375\n",
      "loss 303.82611083984375\n",
      "loss 345.4486389160156\n",
      "loss 494.05853271484375\n",
      "loss 284.9986267089844\n",
      "loss 309.423583984375\n",
      "loss 411.3746032714844\n",
      "loss 430.6236877441406\n",
      "loss 403.42724609375\n",
      "loss 321.299560546875\n",
      "loss 592.3292846679688\n",
      "loss 490.0720520019531\n",
      "loss 459.5335693359375\n",
      "loss 369.4390563964844\n",
      "loss 290.0536193847656\n",
      "loss 699.5924682617188\n",
      "loss 279.15472412109375\n",
      "loss 643.7129516601562\n",
      "loss 394.63226318359375\n",
      "loss 379.89178466796875\n",
      "loss 403.4170227050781\n",
      "loss 488.3524475097656\n",
      "loss 570.7579956054688\n",
      "loss 365.0462951660156\n",
      "loss 302.6119384765625\n",
      "loss 423.2264099121094\n",
      "loss 383.9763488769531\n",
      "loss 413.0032653808594\n",
      "loss 329.7623291015625\n",
      "loss 722.14599609375\n",
      "loss 337.4300842285156\n",
      "loss 370.04168701171875\n",
      "loss 290.3738708496094\n",
      "loss 298.63916015625\n",
      "loss 383.6819152832031\n",
      "loss 457.062255859375\n",
      "loss 272.11968994140625\n",
      "loss 366.9239501953125\n",
      "loss 506.5589904785156\n",
      "loss 288.073974609375\n",
      "loss 452.94732666015625\n",
      "loss 417.317138671875\n",
      "loss 441.9130859375\n",
      "loss 707.5192260742188\n",
      "loss 350.08502197265625\n",
      "loss 231.3910369873047\n",
      "loss 429.4278259277344\n",
      "loss 412.7770690917969\n",
      "loss 387.1591491699219\n",
      "loss 347.5527648925781\n",
      "loss 618.0689086914062\n",
      "loss 454.1148681640625\n",
      "loss 329.9350280761719\n",
      "loss 329.6680908203125\n",
      "loss 394.25885009765625\n",
      "loss 412.35296630859375\n",
      "loss 338.3960876464844\n",
      "loss 373.5263977050781\n",
      "loss 479.850341796875\n",
      "loss 751.2725830078125\n",
      "loss 616.1553344726562\n",
      "loss 248.17649841308594\n",
      "loss 496.2051086425781\n",
      "loss 347.64276123046875\n",
      "loss 410.8924255371094\n",
      "loss 295.9669189453125\n",
      "loss 405.869140625\n",
      "loss 481.0970458984375\n",
      "loss 345.2530517578125\n",
      "loss 388.6044921875\n",
      "loss 434.40509033203125\n",
      "loss 402.0478820800781\n",
      "loss 422.3153381347656\n",
      "loss 293.51678466796875\n",
      "loss 512.4171752929688\n",
      "loss 416.35186767578125\n",
      "loss 357.0746765136719\n",
      "loss 413.20263671875\n",
      "loss 254.5126495361328\n",
      "loss 314.9936828613281\n",
      "loss 258.9471435546875\n",
      "loss 272.4068908691406\n",
      "loss 294.5621337890625\n",
      "loss 390.35064697265625\n",
      "loss 495.55145263671875\n",
      "loss 381.80517578125\n",
      "loss 358.12921142578125\n",
      "loss 247.52947998046875\n",
      "loss 456.2380065917969\n",
      "loss 277.5625\n",
      "loss 403.47381591796875\n",
      "loss 359.7718505859375\n",
      "loss 325.933837890625\n",
      "loss 409.8359069824219\n",
      "loss 491.3957824707031\n",
      "loss 464.310302734375\n",
      "loss 364.841064453125\n",
      "loss 283.94879150390625\n",
      "loss 364.2828369140625\n",
      "loss 591.1104736328125\n",
      "loss 468.008056640625\n",
      "loss 325.69866943359375\n",
      "loss 521.7662353515625\n",
      "loss 467.5870056152344\n",
      "loss 438.11517333984375\n",
      "loss 402.67266845703125\n",
      "loss 343.6477966308594\n",
      "loss 454.066650390625\n",
      "loss 483.5024719238281\n",
      "loss 489.46807861328125\n",
      "loss 313.5549011230469\n",
      "loss 481.1644592285156\n",
      "loss 286.5799560546875\n",
      "loss 391.20843505859375\n",
      "loss 309.0351867675781\n",
      "loss 331.3428039550781\n",
      "loss 484.5829162597656\n",
      "loss 393.447509765625\n",
      "loss 365.9883117675781\n",
      "loss 403.359619140625\n",
      "loss 444.96478271484375\n",
      "tensor([ 0.1597,  0.1602,  0.2033,  0.1276,  0.1277,  0.1325, -0.1907, -0.1877,\n",
      "        -0.2099,  0.0801,  0.0928,  0.0761,  0.1911,  0.1942,  0.2192,  1.0809,\n",
      "         0.1837], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb2a01c2d30>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model training Procedure\n",
    "num_epochs=2000\n",
    "w=torch.randn(17,requires_grad=True)\n",
    "b=torch.randn(1,requires_grad=True)\n",
    "bs=256 #generally powers of 2\n",
    "lr=0.0001\n",
    "\n",
    "losses=[]\n",
    "print(w)\n",
    "for epoch in range(num_epochs):\n",
    "    ll=0\n",
    "    for i,batch in enumerate(iter_data(newMeasurements,results,bs)):\n",
    "        x_batch,y_batch=batch[0],batch[1]\n",
    "        y_hat=Linear_Reg(x_batch,w,b)\n",
    "        loss=Loss_Function(y_hat,y_batch)\n",
    "        ll +=loss\n",
    "        loss.backward()\n",
    "        sgd_step([w,b],lr,len(x_batch))\n",
    "    print(f'loss {loss}')\n",
    "    losses.append(ll.item()/i)\n",
    "\n",
    "print(w)   \n",
    "plt.plot(losses[:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff0f2cf",
   "metadata": {},
   "source": [
    "# Step 10\n",
    "\n",
    "After the training procedure we use the trained parameters for predictions on the whole dataset. We iterated through all the data batches and finally, we calculated the total average loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6c0faa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(404.0110)\n",
      "tensor(384.7487)\n",
      "tensor(390.4334)\n",
      "tensor(315.4136)\n",
      "tensor(413.1219)\n",
      "tensor(367.3969)\n",
      "tensor(381.2802)\n",
      "tensor(444.2348)\n",
      "tensor(443.6051)\n",
      "tensor(358.7421)\n",
      "tensor(393.0565)\n",
      "tensor(370.5641)\n",
      "tensor(494.2720)\n",
      "tensor(358.1895)\n",
      "tensor(474.4608)\n",
      "tensor(416.6631)\n",
      "tensor(396.0587)\n",
      "tensor(402.0932)\n",
      "tensor(300.5665)\n",
      "tensor(458.8990)\n",
      "tensor(359.4384)\n",
      "tensor(466.9780)\n",
      "tensor(428.9382)\n",
      "tensor(468.0628)\n",
      "tensor(320.5005)\n",
      "tensor(470.5842)\n",
      "tensor(480.2803)\n",
      "tensor(403.0075)\n",
      "tensor(436.1693)\n",
      "tensor(387.9509)\n",
      "tensor(311.2054)\n",
      "tensor(410.1387)\n",
      "tensor(487.2819)\n",
      "tensor(477.9733)\n",
      "average loss tensor(408.1271)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    sum=0\n",
    "    for i,batch in enumerate(iter_data(newMeasurements,results,bs)):\n",
    "            x_batch,y_batch=batch[0],batch[1]\n",
    "            y_hat=Linear_Reg(x_batch,w,b)\n",
    "            loss=Loss_Function(y_hat,y_batch)\n",
    "            print(loss)\n",
    "            sum+=loss\n",
    "print(\"average loss\",sum/(i+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f4c802",
   "metadata": {},
   "source": [
    "# Comments\n",
    "\n",
    "We discovered that how important is to choose the learning rate, batch size, and the number of epochs for getting a good value of the loss. In the end, we decided that the best hyperparameter values to obtain the best possible loss values are; learning rate: 0.0001, batch size: 256, and the number of epochs: 2000. And also, we understand that how we can train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50c1a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
